{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOq19nrzlH0p3otvuf3gLl+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/possebon/bigdata-data-management/blob/main/international_tourists.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRs2WUr0BJFV"
      },
      "source": [
        "#Inicialização\n",
        "\n",
        "- Clone do repositório do GitHub\n",
        "- Instalação dos pré-requisitos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TUjxGUqbAOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e50ba23-bda5-4a12-ec9f-b5bd989ea370"
      },
      "source": [
        "import sys\n",
        "!rm * -r -f\n",
        "!git clone https://github.com/possebon/bigdata-data-management.git\n",
        "%cd bigdata-data-management\n",
        "!pip install -r requirements.txt\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bigdata-data-management'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 137 (delta 77), reused 52 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (137/137), 3.16 MiB | 11.55 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n",
            "/content/bigdata-data-management\n",
            "Requirement already satisfied: dnspython==2.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: numpy==1.19.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.19.4)\n",
            "Requirement already satisfied: pandas==1.1.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.1.4)\n",
            "Requirement already satisfied: pymongo==3.11.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (3.11.1)\n",
            "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: pytz==2020.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (2020.4)\n",
            "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.8.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (4.4.1)\n",
            "Requirement already satisfied: plotly-geo in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (1.0.0)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas->-r requirements.txt (line 8)) (1.7.1)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from geopandas->-r requirements.txt (line 8)) (3.0.0.post1)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.6/dist-packages (from geopandas->-r requirements.txt (line 8)) (1.8.18)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->-r requirements.txt (line 9)) (1.3.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from pyproj>=2.2.0->geopandas->-r requirements.txt (line 8)) (2020.11.8)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas->-r requirements.txt (line 8)) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas->-r requirements.txt (line 8)) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas->-r requirements.txt (line 8)) (20.3.0)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas->-r requirements.txt (line 8)) (7.1.2)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas->-r requirements.txt (line 8)) (2.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0n6Kktp8Ese"
      },
      "source": [
        "#Carga dos Dados\n",
        "\n",
        "## Preparação dos dados\n",
        "\n",
        "Ao realizar os dados referente às chegadas dos turistas diretamente do portal do Ministério do Turismo, pudemos identificar uma diferença na estrutura dos arquivos CSV.\n",
        "\n",
        "Foi necessário realizar uma adequação dos arquivos para que ficassem na mesma estrutura e fazer a carga em um único dataframe do Pandas.\n",
        "\n",
        "Optamos pelo tratamento dos arquivos antes da carga ao invés de manipularmos os mesmos no dataframe.\n",
        "\n",
        "Os dados de chegadas não possuem a sigla das Unidades Federativas (UF), somente o nome das UFs.\n",
        "\n",
        "Nossa intentção é de realizar exploração dos dados usando informações georeferenciais, e para isso encontramos dois datasets que contêm essas informações.\n",
        "\n",
        "Estes dois datasets possuem a sigla da UF então criamos um CSV somente com o nome da Unidade Federativa e sua respectiva sigla: uf_sigla.csv\n",
        "\n",
        "No dataset principal, o de chegadas, os nomes das Unidades Federativas não possuem caracteres acentuados.\n",
        "\n",
        "Foi necessário fazer um tratamento, após a carga dos dados para que pudéssemos manter a coerência com os demais datasets que possuem os caracteres acentuados e também na visualização, para que os nomes das respectivas Unidades Federativas exibissem com a correta ortografia.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb5It3or8Sdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb6ae53-de5d-411b-f4f5-4d6adb8af30e"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import sys, getopt, pprint\n",
        "from pymongo import MongoClient\n",
        "from calendar import monthrange\n",
        "import datetime\n",
        "import os\n",
        "import glob\n",
        "import geopandas\n",
        "import requests\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def parse_date_value(year, month):\n",
        "    # The date information on dataset it's only month name in Portuguese \n",
        "    # and the year with 4 digits\n",
        "    # we need to convert this information to a datetime field\n",
        "\n",
        "    month_name = {'Janeiro': 'January', 'Fevereiro': 'February', \n",
        "                  'Marco': 'March', 'Março': 'March', 'Abril': 'April', \n",
        "                  'Maio': 'May', 'Junho': 'June', 'Julho': 'July', \n",
        "                  'Agosto': 'August', 'Setembro': 'September', \n",
        "                  'Outubro':'October', 'Novembro':'November', \n",
        "                  'Dezembro': 'December'}\n",
        "\n",
        "    datetime_object = datetime.datetime.strptime(month_name[month], \"%B\")\n",
        "    month_number = format(datetime_object.month,'02')\n",
        "    date_str = year + '-' + month_number + '-01 23:59:59'\n",
        "    date_time_obj = datetime.datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
        "    return date_time_obj.replace(day = monthrange(date_time_obj.year, \n",
        "                                                  date_time_obj.month)[1])\n",
        "\n",
        "data_path = './data'\n",
        "\n",
        "ufs = {'Amapa': 'Amapá', 'Ceara' : 'Ceará', 'Espirito Santo' : 'Espírito Santo',\n",
        "       'Goias' : 'Goiás', 'Maranhao' : 'Maranhão', 'Para' : 'Pará', \n",
        "       'Paraiba' : 'Paraíba', 'Parana' : 'Paraná', 'Rondonia' : 'Rondônia', \n",
        "       'Sao Paulo': 'São Paulo' }\n",
        "\n",
        "\n",
        "\n",
        "df = pd.concat([pd.read_csv(f) for f in glob.glob(data_path + \"/chegadas*.csv\")],\n",
        "                      ignore_index=True)\n",
        "\n",
        "\n",
        "df['Ano'] = df['Ano'].astype(str)\n",
        "df['Mes'] = df['Mes'].astype(str)\n",
        "\n",
        "\n",
        "df['date_value'] = df.apply(lambda x: parse_date_value(x['Ano'], x['Mes']), \n",
        "                            axis=1)\n",
        "\n",
        "df.loc[(df.Via == 'Aerea'),'Via']='Aérea'\n",
        "df.loc[(df.Via == 'Maritima'),'Via']='Marítima'\n",
        "\n",
        "# Update the UF names after the load\n",
        "for uf in ufs:\n",
        "  df.loc[df['Estado'] == uf, 'Estado'] = ufs[uf]\n",
        "\n",
        "\n",
        "# Load UF Codes\n",
        "df_uf_codes = pd.read_csv(data_path + \"/uf_sigla.csv\", encoding=\"utf-8\")\n",
        "\n",
        "# Load UF Coordinates\n",
        "df_uf_points = pd.read_csv(data_path + \"/coordenadas_ufs.csv\", encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "# UF GeoJSON data\n",
        "df_uf_polygons = pd.read_json('./data/uf_polygons.json', encoding = \"utf-8\")\n",
        "\n",
        "database = \"international-tourists\"\n",
        "\n",
        "mongo_uri = \"mongodb+srv://bigdata:k9Wqj6n9qn9Kklkv@cluster0.h7q5i.mongodb.net/test?retryWrites=true&w=majority\"\n",
        "client = MongoClient(mongo_uri)\n",
        "\n",
        "db = client[database]\n",
        "\n",
        "if ('arrivals' in db.list_collection_names()):\n",
        "  collection = db['arrivals']\n",
        "  collection.drop()\n",
        "\n",
        "if ('uf_polygons' in db.list_collection_names()):\n",
        "  collection = db['uf_polygons']\n",
        "  collection.drop()\n",
        "\n",
        "if ('uf_points' in db.list_collection_names()):\n",
        "  collection = db['uf_points']\n",
        "  collection.drop()\n",
        "\n",
        "if ('uf_codes' in db.list_collection_names()):\n",
        "  collection = db['uf_codes']\n",
        "  collection.drop()\n",
        "\n",
        "\n",
        "collection = db['arrivals']\n",
        "\n",
        "df.reset_index(inplace=True)\n",
        "data_dict = df.to_dict(\"records\")\n",
        "# Insert collection\n",
        "collection.insert_many(data_dict)\n",
        "\n",
        "# Insert UF_polygons collection\n",
        "df_uf_polygons.reset_index(inplace=True)\n",
        "data_dict = df_uf_polygons.to_dict(\"records\")\n",
        "\n",
        "collection = db['uf_polygons']\n",
        "collection.insert_many(data_dict)\n",
        "\n",
        "# Insert UF_points collection\n",
        "df_uf_points.reset_index(inplace=True)\n",
        "data_dict = df_uf_points.to_dict(\"records\")\n",
        "\n",
        "collection = db['uf_points']\n",
        "collection.insert_many(data_dict)\n",
        "\n",
        "# Insert UF_codes collection\n",
        "df_uf_codes.reset_index(inplace=True)\n",
        "data_dict = df_uf_codes.to_dict(\"records\")\n",
        "\n",
        "collection = db['uf_codes']\n",
        "collection.insert_many(data_dict)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pymongo.results.InsertManyResult at 0x7f3456365f88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}